{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Models with priors that lack quantiles\n",
    "In JAXNS the priors are formulated in a base probability measure, that is always the $\\mu = U[0,1]$ measure.\n",
    "In this situation, the push-forward measure is given by the quantile function, i.e. inverse of the cumulative distribution function.\n",
    "\n",
    "Mathematically, given a measureable space $(\\mathcal{X}, \\Sigma_1)$ and a measurable function $F : (\\mathcal{X}, \\Sigma_1) \\to ([0, 1], \\Sigma_2)$, then the push-forward measure of a base measure $\\mu : \\Sigma_1 \\to \\mathbb{R}^+$ is,\n",
    "\n",
    "$F_*\\mu(B) = \\mu(F^{-1}(B)) \\quad \\forall B \\in \\Sigma_2$.\n",
    "\n",
    "For strictly monotonic measurable functions, $F$, $\\Sigma_1$ and $\\Sigma_2$ can simply be the Borel sigma-algebras, and $F^{-1}$ is the quantile function.\n",
    "\n",
    "When the quantile function is easily computable this opens up a way to treat all our priors in a homogeneous manner, by representing them as transformations from a uniformly distributed RV.\n",
    "\n",
    "This is attractive, because this turns our model into a dimensionless problem, and in fact, we could think our base measures as having units of probability.\n",
    "\n",
    "Under this transformation, our evidence calculation becomes (in one dimension),\n",
    "\n",
    "$Z \\triangleq p(y) = \\int_{\\mathcal{X}} L(x) p(x) \\, \\mathrm{d} x = \\int_0^1 L(F^{-1}(u)) \\, \\mathrm{d} u$,\n",
    "\n",
    "where $\\mathrm{d}u$ is the Lebesgue measure on $[0,1]$.\n",
    "\n",
    "This generalises in a straight-forward manner to high dimensions.\n",
    "\n",
    "## When you don't have a qunatile function\n",
    "\n",
    "When we don't have a quantile function, then we are not lost.\n",
    "In this case, we apply a different parametrisation. Namely we choose a different bijective mesaurable function $G:(\\mathcal{X}, \\Sigma_1) \\to ([0,1]], \\Sigma_2)$, which does have an easy to compute inverse, $G^{-1}$.\n",
    "\n",
    "Furthermore, let $F$ and $G$ be absolutely continuous with respect to the base measure, $F \\ll \\mu$ and $G \\ll \\mu$ respectively, then they have Radon-Nikodym derivatives, $f \\triangleq \\frac{\\mathrm{d}F}{\\mathrm{d} \\mu}$ and $g \\triangleq \\frac{\\mathrm{d}G}{\\mathrm{d} \\mu}$ respectively, which we call the probability densities.\n",
    "\n",
    "It is then straight-forward to show that,\n",
    "\n",
    "$Z \\triangleq p(y) = \\int_{\\mathcal{X}} L(x) p(x) \\, \\mathrm{d} x = \\int_0^1 L(G^{-1}(u)) \\frac{f(G^{-1}(u))}{g(G^{-1}(u))} \\, \\mathrm{d} u$.\n",
    "\n",
    "It then becomes a simple matter to deal with priors lacking a quantile. Importantly, we require the support of $G$ to contain the suppor of $F$, i.e. $F\\ll G$.\n",
    "\n",
    "Note: if you don't care about the scale of the evidence, e.g. you're only doing parameter inference, then $f$ need not be normalised. Another case where it doesn't matter, would be if you're trying different likelihoods, but keeping the priors the same, then relative evidence ratios are all you care about. **However, if you will use the evidence to compare with other models, then it must be normalised either analytically or numerically.**\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll cover the following topics:\n",
    "\n",
    "1. Two built in priors without quantiles: `GammaPrior` and `StudentTPrior`.\n",
    "2. How to define your own prior without a quantile, but with a known probability density function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from jaxns import NestedSampler\n",
    "from jaxns.prior_transforms import PriorChain, GammaPrior, StudentT, RealPrior, get_shape\n",
    "from jaxns.internals.shapes import broadcast_shapes\n",
    "from jaxns.utils import summary, resample\n",
    "from jaxns.plotting import plot_cornerplot, plot_diagnostics\n",
    "from jax import random, numpy as jnp, vmap\n",
    "from jax.scipy.special import gammaln\n",
    "import pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_k = 1.\n",
    "true_theta = 0.5\n",
    "\n",
    "print(\"True log(Z)=0\")\n",
    "\n",
    "\n",
    "def log_likelihood(gamma):\n",
    "    \"\"\"\n",
    "    Unit likelihood\n",
    "    \"\"\"\n",
    "    return 0.\n",
    "\n",
    "\n",
    "with PriorChain() as prior_chain:\n",
    "    gamma = GammaPrior('gamma', true_k, true_theta)\n",
    "\n",
    "ns = NestedSampler(loglikelihood=log_likelihood,\n",
    "                   prior_chain=prior_chain)\n",
    "\n",
    "results = ns(random.PRNGKey(32564))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Summary looks good\n",
    "summary(results)\n",
    "plot_diagnostics(results)\n",
    "plot_cornerplot(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Posteriors match well\n",
    "samples = resample(random.PRNGKey(43083245), results.samples, results.log_dp_mean, S=int(results.ESS))\n",
    "\n",
    "plt.hist(samples['gamma'], bins='auto', ec='cyan', alpha=0.5, density=True, fc='none')\n",
    "\n",
    "_gamma = np.random.gamma(true_k, true_theta, size=100000)\n",
    "\n",
    "plt.hist(_gamma, bins='auto', ec='orange', alpha=0.05, density=True, fc='none')\n",
    "\n",
    "\n",
    "_x = jnp.linspace(0, 5, 1000)\n",
    "_log_prob = vmap(lambda _x: gamma._log_prob(_x, true_k, true_theta))(_x)\n",
    "plt.plot(_x,jnp.exp(_log_prob), c='orange')\n",
    "plt.xlim(0, 5.)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_nu, true_mu, true_sigma = 2., 0., 1.\n",
    "\n",
    "print(\"True log(Z)=0\")\n",
    "\n",
    "\n",
    "def log_likelihood(x, **kwargs):\n",
    "    \"\"\"\n",
    "    Unit likelihood\n",
    "    \"\"\"\n",
    "    return 0.\n",
    "\n",
    "\n",
    "with PriorChain() as prior_chain:\n",
    "    x = StudentT('x', true_nu, true_mu, true_sigma)\n",
    "\n",
    "ns = NestedSampler(loglikelihood=log_likelihood,\n",
    "                   prior_chain=prior_chain)\n",
    "\n",
    "results = ns(random.PRNGKey(32564))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "summary(results)\n",
    "plot_diagnostics(results)\n",
    "plot_cornerplot(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "samples = resample(random.PRNGKey(43083245), results.samples, results.log_dp_mean, S=int(results.ESS))\n",
    "\n",
    "plt.hist(samples['x'], bins='auto', ec='cyan', alpha=0.5, density=True, fc='none')\n",
    "\n",
    "_x = np.random.standard_t(true_nu, size=100000)\n",
    "\n",
    "plt.hist(_x, bins='auto', ec='orange', alpha=0.05, density=True, fc='none')\n",
    "\n",
    "_x = jnp.linspace(-10, 10, 1000)\n",
    "_log_prob = vmap(lambda _x: x._log_prob(_x, true_nu, true_mu, true_sigma))(_x)\n",
    "plt.plot(_x,jnp.exp(_log_prob), c='orange')\n",
    "plt.xlim(-10., 10.)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# When there are no quantiles for a prior that you want to implement, then there's an easy way to implement your own Prior.\n",
    "\n",
    "\n",
    "class GeneralisedGaussianPrior(RealPrior):\n",
    "    \"\"\"\n",
    "    Generalises the Gaussian from L2 norm to Lp.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, mu, alpha, beta, tracked=True):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            mu: location\n",
    "            alpha: scale\n",
    "            beta: shape\n",
    "        \"\"\"\n",
    "        mu = self._prepare_parameter(name, 'mu', mu)\n",
    "        alpha = self._prepare_parameter(name, 'alpha', alpha)\n",
    "        beta = self._prepare_parameter(name, 'beta', beta)\n",
    "        shape = broadcast_shapes(broadcast_shapes(get_shape(mu), get_shape(alpha)),\n",
    "                                 get_shape(beta))\n",
    "        super(GeneralisedGaussianPrior, self).__init__(name, shape, [mu, alpha, beta], tracked)\n",
    "\n",
    "    def _support_center(self, mu, alpha, beta):\n",
    "        \"\"\"\n",
    "        We return mode.\n",
    "        \"\"\"\n",
    "        return mu\n",
    "\n",
    "    def _support_width(self, mu, alpha, beta):\n",
    "        \"\"\"\n",
    "        We use the FWHM.\n",
    "        \"\"\"\n",
    "        fwhm = 2. * alpha * jnp.power(np.log(2.), jnp.reciprocal(beta))\n",
    "        return fwhm\n",
    "\n",
    "    def _log_prob(self, X, mu, alpha, beta):\n",
    "        \"\"\"\n",
    "        Student-T log-prob.\n",
    "        \"\"\"\n",
    "        return - np.log(2.) + jnp.log(beta) - jnp.log(alpha) - gammaln(jnp.reciprocal(beta)) - jnp.power(\n",
    "            jnp.abs(X - mu) / alpha, beta)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"True log(Z)=0\")\n",
    "\n",
    "def log_likelihood(x):\n",
    "    \"\"\"\n",
    "    Unit likelihood\n",
    "    \"\"\"\n",
    "    return 0.\n",
    "\n",
    "\n",
    "with PriorChain() as prior_chain:\n",
    "    x = GeneralisedGaussianPrior('x', 0., 1., 1.5)\n",
    "\n",
    "ns = NestedSampler(loglikelihood=log_likelihood,\n",
    "                   prior_chain=prior_chain)\n",
    "\n",
    "results = ns(random.PRNGKey(32564), num_live_points=1000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary(results)\n",
    "plot_diagnostics(results)\n",
    "plot_cornerplot(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "samples = resample(random.PRNGKey(43083245), results.samples, results.log_dp_mean, S=int(results.ESS))\n",
    "\n",
    "plt.hist(samples['x'], bins='auto', ec='cyan', alpha=0.5, density=True, fc='none')\n",
    "\n",
    "_x = jnp.linspace(-10, 10, 1000)\n",
    "_log_prob = vmap(lambda _x: x._log_prob(_x, 0., 1., 1.5))(_x)\n",
    "plt.plot(_x,jnp.exp(_log_prob), c='orange')\n",
    "plt.xlim(-10., 10.)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "samples = resample(random.PRNGKey(43083245), results.samples, results.log_dp_mean, S=int(results.ESS))\n",
    "\n",
    "plt.hist(samples['x'], bins='auto', ec='blue', alpha=0.5, density=True, fc='none')\n",
    "\n",
    "_x = np.random.standard_t(true_nu, size=100000)\n",
    "\n",
    "plt.hist(_x, bins='auto', ec='orange', alpha=0.5, density=True, fc='none')\n",
    "plt.xlim(-10., 10.)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "summary(results)\n",
    "plot_diagnostics(results)\n",
    "plot_cornerplot(results)\n",
    "\n",
    "samples = resample(random.PRNGKey(43083245), results.samples, results.log_dp_mean, S=int(results.ESS))\n",
    "\n",
    "plt.hist(samples['x'], bins='auto', ec='blue', alpha=0.5, density=True, fc='none')\n",
    "\n",
    "_x = np.random.standard_t(true_nu, size=100000)\n",
    "\n",
    "plt.hist(_x, bins='auto', ec='orange', alpha=0.5, density=True, fc='none')\n",
    "plt.xlim(-10., 10.)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_nu, true_mu, true_sigma = 2., 0., 1.\n",
    "\n",
    "def log_likelihood(x, **kwargs):\n",
    "    \"\"\"\n",
    "    Unit likelihood\n",
    "    \"\"\"\n",
    "    return 0.\n",
    "\n",
    "with PriorChain() as prior_chain:\n",
    "    StudentT('x', true_nu, true_mu, true_sigma)\n",
    "ns = NestedSampler(loglikelihood=log_likelihood,\n",
    "                   prior_chain=prior_chain)\n",
    "\n",
    "results = ns(random.PRNGKey(32564))\n",
    "summary(results)\n",
    "plot_diagnostics(results)\n",
    "plot_cornerplot(results)\n",
    "\n",
    "samples = resample(random.PRNGKey(43083245), results.samples, results.log_dp_mean, S=int(results.ESS))\n",
    "\n",
    "plt.hist(samples['x'], bins='auto', ec='blue', alpha=0.5, density=True, fc='none')\n",
    "\n",
    "_x = np.random.standard_t(true_nu, size=100000)\n",
    "\n",
    "plt.hist(_x, bins='auto', ec='orange', alpha=0.5, density=True, fc='none')\n",
    "plt.xlim(-10., 10.)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}