{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gradient-free Global Maximum Likelihood Finding: Neural Networks\n",
    "\n",
    "Neural network training is typically done with maximum likelihood estimation. Given the number of parameter invariances, and symmetries in neural network architectures, this often introduces a large number of local minima, making global optimisation very difficult.\n",
    "\n",
    "JAXNS uses slice sampling as a gradient-free way to sample from hard-likelihood constraints, starting from small likelihoods and strictly increasing towards a maximum likelihood. This actually means that JAXNS is performing global maximisation of the likelihood. The prior can be seen as a measure which guides where JAXNS looks first. An attractive idea is to think about the prior as a guide for efficient global maximisation with JAXNS, but that's for another tutorial ;).\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial we'll cover:\n",
    "1. How to build a JAXNS model of a neural network using [Haiku](https://github.com/deepmind/dm-haiku)\n",
    "2. How to do global likelihood maximisation with JAXNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "try:\n",
    "    import haiku as hk\n",
    "except ImportError:\n",
    "    raise ImportError(\"You must `pip install dm-haiku` first.\")\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import roc_curve\n",
    "except:\n",
    "    raise ImportError(\"You must `pip install scikit-learn`\")\n",
    "\n",
    "from jax import numpy as jnp, random, vmap\n",
    "import jax\n",
    "from jax.flatten_util import ravel_pytree\n",
    "\n",
    "from jaxns.prior_transforms import UniformPrior, PriorChain\n",
    "from jaxns import GlobalOptimiser\n",
    "from jax.scipy.optimize import minimize\n",
    "from itertools import product\n",
    "import pylab as plt\n",
    "\n",
    "# for parallel sampling\n",
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count=4\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[2022-04-06 16:57:12,931]: No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.] -> [False]\n",
      "[1. 1. 1. 1. 1. 1. 1. 0.] -> [ True]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1.] -> [ True]\n",
      "[1. 1. 1. 1. 1. 1. 0. 0.] -> [False]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1.] -> [ True]\n",
      "[1. 1. 1. 1. 1. 0. 1. 0.] -> [False]\n",
      "[1. 1. 1. 1. 1. 0. 0. 1.] -> [False]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0.] -> [ True]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1.] -> [ True]\n",
      "[1. 1. 1. 1. 0. 1. 1. 0.] -> [False]\n",
      "[1. 1. 1. 1. 0. 1. 0. 1.] -> [False]\n",
      "[1. 1. 1. 1. 0. 1. 0. 0.] -> [ True]\n",
      "[1. 1. 1. 1. 0. 0. 1. 1.] -> [False]\n",
      "[1. 1. 1. 1. 0. 0. 1. 0.] -> [ True]\n",
      "[1. 1. 1. 1. 0. 0. 0. 1.] -> [ True]\n",
      "[1. 1. 1. 1. 0. 0. 0. 0.] -> [False]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1.] -> [ True]\n",
      "[1. 1. 1. 0. 1. 1. 1. 0.] -> [False]\n",
      "[1. 1. 1. 0. 1. 1. 0. 1.] -> [False]\n",
      "[1. 1. 1. 0. 1. 1. 0. 0.] -> [ True]\n",
      "[1. 1. 1. 0. 1. 0. 1. 1.] -> [False]\n",
      "[1. 1. 1. 0. 1. 0. 1. 0.] -> [ True]\n",
      "[1. 1. 1. 0. 1. 0. 0. 1.] -> [ True]\n",
      "[1. 1. 1. 0. 1. 0. 0. 0.] -> [False]\n",
      "[1. 1. 1. 0. 0. 1. 1. 1.] -> [False]\n",
      "[1. 1. 1. 0. 0. 1. 1. 0.] -> [ True]\n",
      "[1. 1. 1. 0. 0. 1. 0. 1.] -> [ True]\n",
      "[1. 1. 1. 0. 0. 1. 0. 0.] -> [False]\n",
      "[1. 1. 1. 0. 0. 0. 1. 1.] -> [ True]\n",
      "[1. 1. 1. 0. 0. 0. 1. 0.] -> [False]\n",
      "[1. 1. 1. 0. 0. 0. 0. 1.] -> [False]\n",
      "[1. 1. 1. 0. 0. 0. 0. 0.] -> [ True]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1.] -> [ True]\n",
      "[1. 1. 0. 1. 1. 1. 1. 0.] -> [False]\n",
      "[1. 1. 0. 1. 1. 1. 0. 1.] -> [False]\n",
      "[1. 1. 0. 1. 1. 1. 0. 0.] -> [ True]\n",
      "[1. 1. 0. 1. 1. 0. 1. 1.] -> [False]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0.] -> [ True]\n",
      "[1. 1. 0. 1. 1. 0. 0. 1.] -> [ True]\n",
      "[1. 1. 0. 1. 1. 0. 0. 0.] -> [False]\n",
      "[1. 1. 0. 1. 0. 1. 1. 1.] -> [False]\n",
      "[1. 1. 0. 1. 0. 1. 1. 0.] -> [ True]\n",
      "[1. 1. 0. 1. 0. 1. 0. 1.] -> [ True]\n",
      "[1. 1. 0. 1. 0. 1. 0. 0.] -> [False]\n",
      "[1. 1. 0. 1. 0. 0. 1. 1.] -> [ True]\n",
      "[1. 1. 0. 1. 0. 0. 1. 0.] -> [False]\n",
      "[1. 1. 0. 1. 0. 0. 0. 1.] -> [False]\n",
      "[1. 1. 0. 1. 0. 0. 0. 0.] -> [ True]\n",
      "[1. 1. 0. 0. 1. 1. 1. 1.] -> [False]\n",
      "[1. 1. 0. 0. 1. 1. 1. 0.] -> [ True]\n",
      "[1. 1. 0. 0. 1. 1. 0. 1.] -> [ True]\n",
      "[1. 1. 0. 0. 1. 1. 0. 0.] -> [False]\n",
      "[1. 1. 0. 0. 1. 0. 1. 1.] -> [ True]\n",
      "[1. 1. 0. 0. 1. 0. 1. 0.] -> [False]\n",
      "[1. 1. 0. 0. 1. 0. 0. 1.] -> [False]\n",
      "[1. 1. 0. 0. 1. 0. 0. 0.] -> [ True]\n",
      "[1. 1. 0. 0. 0. 1. 1. 1.] -> [ True]\n",
      "[1. 1. 0. 0. 0. 1. 1. 0.] -> [False]\n",
      "[1. 1. 0. 0. 0. 1. 0. 1.] -> [False]\n",
      "[1. 1. 0. 0. 0. 1. 0. 0.] -> [ True]\n",
      "[1. 1. 0. 0. 0. 0. 1. 1.] -> [False]\n",
      "[1. 1. 0. 0. 0. 0. 1. 0.] -> [ True]\n",
      "[1. 1. 0. 0. 0. 0. 0. 1.] -> [ True]\n",
      "[1. 1. 0. 0. 0. 0. 0. 0.] -> [False]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1.] -> [ True]\n",
      "[1. 0. 1. 1. 1. 1. 1. 0.] -> [False]\n",
      "[1. 0. 1. 1. 1. 1. 0. 1.] -> [False]\n",
      "[1. 0. 1. 1. 1. 1. 0. 0.] -> [ True]\n",
      "[1. 0. 1. 1. 1. 0. 1. 1.] -> [False]\n",
      "[1. 0. 1. 1. 1. 0. 1. 0.] -> [ True]\n",
      "[1. 0. 1. 1. 1. 0. 0. 1.] -> [ True]\n",
      "[1. 0. 1. 1. 1. 0. 0. 0.] -> [False]\n",
      "[1. 0. 1. 1. 0. 1. 1. 1.] -> [False]\n",
      "[1. 0. 1. 1. 0. 1. 1. 0.] -> [ True]\n",
      "[1. 0. 1. 1. 0. 1. 0. 1.] -> [ True]\n",
      "[1. 0. 1. 1. 0. 1. 0. 0.] -> [False]\n",
      "[1. 0. 1. 1. 0. 0. 1. 1.] -> [ True]\n",
      "[1. 0. 1. 1. 0. 0. 1. 0.] -> [False]\n",
      "[1. 0. 1. 1. 0. 0. 0. 1.] -> [False]\n",
      "[1. 0. 1. 1. 0. 0. 0. 0.] -> [ True]\n",
      "[1. 0. 1. 0. 1. 1. 1. 1.] -> [False]\n",
      "[1. 0. 1. 0. 1. 1. 1. 0.] -> [ True]\n",
      "[1. 0. 1. 0. 1. 1. 0. 1.] -> [ True]\n",
      "[1. 0. 1. 0. 1. 1. 0. 0.] -> [False]\n",
      "[1. 0. 1. 0. 1. 0. 1. 1.] -> [ True]\n",
      "[1. 0. 1. 0. 1. 0. 1. 0.] -> [False]\n",
      "[1. 0. 1. 0. 1. 0. 0. 1.] -> [False]\n",
      "[1. 0. 1. 0. 1. 0. 0. 0.] -> [ True]\n",
      "[1. 0. 1. 0. 0. 1. 1. 1.] -> [ True]\n",
      "[1. 0. 1. 0. 0. 1. 1. 0.] -> [False]\n",
      "[1. 0. 1. 0. 0. 1. 0. 1.] -> [False]\n",
      "[1. 0. 1. 0. 0. 1. 0. 0.] -> [ True]\n",
      "[1. 0. 1. 0. 0. 0. 1. 1.] -> [False]\n",
      "[1. 0. 1. 0. 0. 0. 1. 0.] -> [ True]\n",
      "[1. 0. 1. 0. 0. 0. 0. 1.] -> [ True]\n",
      "[1. 0. 1. 0. 0. 0. 0. 0.] -> [False]\n",
      "[1. 0. 0. 1. 1. 1. 1. 1.] -> [False]\n",
      "[1. 0. 0. 1. 1. 1. 1. 0.] -> [ True]\n",
      "[1. 0. 0. 1. 1. 1. 0. 1.] -> [ True]\n",
      "[1. 0. 0. 1. 1. 1. 0. 0.] -> [False]\n",
      "[1. 0. 0. 1. 1. 0. 1. 1.] -> [ True]\n",
      "[1. 0. 0. 1. 1. 0. 1. 0.] -> [False]\n",
      "[1. 0. 0. 1. 1. 0. 0. 1.] -> [False]\n",
      "[1. 0. 0. 1. 1. 0. 0. 0.] -> [ True]\n",
      "[1. 0. 0. 1. 0. 1. 1. 1.] -> [ True]\n",
      "[1. 0. 0. 1. 0. 1. 1. 0.] -> [False]\n",
      "[1. 0. 0. 1. 0. 1. 0. 1.] -> [False]\n",
      "[1. 0. 0. 1. 0. 1. 0. 0.] -> [ True]\n",
      "[1. 0. 0. 1. 0. 0. 1. 1.] -> [False]\n",
      "[1. 0. 0. 1. 0. 0. 1. 0.] -> [ True]\n",
      "[1. 0. 0. 1. 0. 0. 0. 1.] -> [ True]\n",
      "[1. 0. 0. 1. 0. 0. 0. 0.] -> [False]\n",
      "[1. 0. 0. 0. 1. 1. 1. 1.] -> [ True]\n",
      "[1. 0. 0. 0. 1. 1. 1. 0.] -> [False]\n",
      "[1. 0. 0. 0. 1. 1. 0. 1.] -> [False]\n",
      "[1. 0. 0. 0. 1. 1. 0. 0.] -> [ True]\n",
      "[1. 0. 0. 0. 1. 0. 1. 1.] -> [False]\n",
      "[1. 0. 0. 0. 1. 0. 1. 0.] -> [ True]\n",
      "[1. 0. 0. 0. 1. 0. 0. 1.] -> [ True]\n",
      "[1. 0. 0. 0. 1. 0. 0. 0.] -> [False]\n",
      "[1. 0. 0. 0. 0. 1. 1. 1.] -> [False]\n",
      "[1. 0. 0. 0. 0. 1. 1. 0.] -> [ True]\n",
      "[1. 0. 0. 0. 0. 1. 0. 1.] -> [ True]\n",
      "[1. 0. 0. 0. 0. 1. 0. 0.] -> [False]\n",
      "[1. 0. 0. 0. 0. 0. 1. 1.] -> [ True]\n",
      "[1. 0. 0. 0. 0. 0. 1. 0.] -> [False]\n",
      "[1. 0. 0. 0. 0. 0. 0. 1.] -> [False]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.] -> [ True]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1.] -> [ True]\n",
      "[0. 1. 1. 1. 1. 1. 1. 0.] -> [False]\n",
      "[0. 1. 1. 1. 1. 1. 0. 1.] -> [False]\n",
      "[0. 1. 1. 1. 1. 1. 0. 0.] -> [ True]\n",
      "[0. 1. 1. 1. 1. 0. 1. 1.] -> [False]\n",
      "[0. 1. 1. 1. 1. 0. 1. 0.] -> [ True]\n",
      "[0. 1. 1. 1. 1. 0. 0. 1.] -> [ True]\n",
      "[0. 1. 1. 1. 1. 0. 0. 0.] -> [False]\n",
      "[0. 1. 1. 1. 0. 1. 1. 1.] -> [False]\n",
      "[0. 1. 1. 1. 0. 1. 1. 0.] -> [ True]\n",
      "[0. 1. 1. 1. 0. 1. 0. 1.] -> [ True]\n",
      "[0. 1. 1. 1. 0. 1. 0. 0.] -> [False]\n",
      "[0. 1. 1. 1. 0. 0. 1. 1.] -> [ True]\n",
      "[0. 1. 1. 1. 0. 0. 1. 0.] -> [False]\n",
      "[0. 1. 1. 1. 0. 0. 0. 1.] -> [False]\n",
      "[0. 1. 1. 1. 0. 0. 0. 0.] -> [ True]\n",
      "[0. 1. 1. 0. 1. 1. 1. 1.] -> [False]\n",
      "[0. 1. 1. 0. 1. 1. 1. 0.] -> [ True]\n",
      "[0. 1. 1. 0. 1. 1. 0. 1.] -> [ True]\n",
      "[0. 1. 1. 0. 1. 1. 0. 0.] -> [False]\n",
      "[0. 1. 1. 0. 1. 0. 1. 1.] -> [ True]\n",
      "[0. 1. 1. 0. 1. 0. 1. 0.] -> [False]\n",
      "[0. 1. 1. 0. 1. 0. 0. 1.] -> [False]\n",
      "[0. 1. 1. 0. 1. 0. 0. 0.] -> [ True]\n",
      "[0. 1. 1. 0. 0. 1. 1. 1.] -> [ True]\n",
      "[0. 1. 1. 0. 0. 1. 1. 0.] -> [False]\n",
      "[0. 1. 1. 0. 0. 1. 0. 1.] -> [False]\n",
      "[0. 1. 1. 0. 0. 1. 0. 0.] -> [ True]\n",
      "[0. 1. 1. 0. 0. 0. 1. 1.] -> [False]\n",
      "[0. 1. 1. 0. 0. 0. 1. 0.] -> [ True]\n",
      "[0. 1. 1. 0. 0. 0. 0. 1.] -> [ True]\n",
      "[0. 1. 1. 0. 0. 0. 0. 0.] -> [False]\n",
      "[0. 1. 0. 1. 1. 1. 1. 1.] -> [False]\n",
      "[0. 1. 0. 1. 1. 1. 1. 0.] -> [ True]\n",
      "[0. 1. 0. 1. 1. 1. 0. 1.] -> [ True]\n",
      "[0. 1. 0. 1. 1. 1. 0. 0.] -> [False]\n",
      "[0. 1. 0. 1. 1. 0. 1. 1.] -> [ True]\n",
      "[0. 1. 0. 1. 1. 0. 1. 0.] -> [False]\n",
      "[0. 1. 0. 1. 1. 0. 0. 1.] -> [False]\n",
      "[0. 1. 0. 1. 1. 0. 0. 0.] -> [ True]\n",
      "[0. 1. 0. 1. 0. 1. 1. 1.] -> [ True]\n",
      "[0. 1. 0. 1. 0. 1. 1. 0.] -> [False]\n",
      "[0. 1. 0. 1. 0. 1. 0. 1.] -> [False]\n",
      "[0. 1. 0. 1. 0. 1. 0. 0.] -> [ True]\n",
      "[0. 1. 0. 1. 0. 0. 1. 1.] -> [False]\n",
      "[0. 1. 0. 1. 0. 0. 1. 0.] -> [ True]\n",
      "[0. 1. 0. 1. 0. 0. 0. 1.] -> [ True]\n",
      "[0. 1. 0. 1. 0. 0. 0. 0.] -> [False]\n",
      "[0. 1. 0. 0. 1. 1. 1. 1.] -> [ True]\n",
      "[0. 1. 0. 0. 1. 1. 1. 0.] -> [False]\n",
      "[0. 1. 0. 0. 1. 1. 0. 1.] -> [False]\n",
      "[0. 1. 0. 0. 1. 1. 0. 0.] -> [ True]\n",
      "[0. 1. 0. 0. 1. 0. 1. 1.] -> [False]\n",
      "[0. 1. 0. 0. 1. 0. 1. 0.] -> [ True]\n",
      "[0. 1. 0. 0. 1. 0. 0. 1.] -> [ True]\n",
      "[0. 1. 0. 0. 1. 0. 0. 0.] -> [False]\n",
      "[0. 1. 0. 0. 0. 1. 1. 1.] -> [False]\n",
      "[0. 1. 0. 0. 0. 1. 1. 0.] -> [ True]\n",
      "[0. 1. 0. 0. 0. 1. 0. 1.] -> [ True]\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] -> [False]\n",
      "[0. 1. 0. 0. 0. 0. 1. 1.] -> [ True]\n",
      "[0. 1. 0. 0. 0. 0. 1. 0.] -> [False]\n",
      "[0. 1. 0. 0. 0. 0. 0. 1.] -> [False]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0.] -> [ True]\n",
      "[0. 0. 1. 1. 1. 1. 1. 1.] -> [False]\n",
      "[0. 0. 1. 1. 1. 1. 1. 0.] -> [ True]\n",
      "[0. 0. 1. 1. 1. 1. 0. 1.] -> [ True]\n",
      "[0. 0. 1. 1. 1. 1. 0. 0.] -> [False]\n",
      "[0. 0. 1. 1. 1. 0. 1. 1.] -> [ True]\n",
      "[0. 0. 1. 1. 1. 0. 1. 0.] -> [False]\n",
      "[0. 0. 1. 1. 1. 0. 0. 1.] -> [False]\n",
      "[0. 0. 1. 1. 1. 0. 0. 0.] -> [ True]\n",
      "[0. 0. 1. 1. 0. 1. 1. 1.] -> [ True]\n",
      "[0. 0. 1. 1. 0. 1. 1. 0.] -> [False]\n",
      "[0. 0. 1. 1. 0. 1. 0. 1.] -> [False]\n",
      "[0. 0. 1. 1. 0. 1. 0. 0.] -> [ True]\n",
      "[0. 0. 1. 1. 0. 0. 1. 1.] -> [False]\n",
      "[0. 0. 1. 1. 0. 0. 1. 0.] -> [ True]\n",
      "[0. 0. 1. 1. 0. 0. 0. 1.] -> [ True]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0.] -> [False]\n",
      "[0. 0. 1. 0. 1. 1. 1. 1.] -> [ True]\n",
      "[0. 0. 1. 0. 1. 1. 1. 0.] -> [False]\n",
      "[0. 0. 1. 0. 1. 1. 0. 1.] -> [False]\n",
      "[0. 0. 1. 0. 1. 1. 0. 0.] -> [ True]\n",
      "[0. 0. 1. 0. 1. 0. 1. 1.] -> [False]\n",
      "[0. 0. 1. 0. 1. 0. 1. 0.] -> [ True]\n",
      "[0. 0. 1. 0. 1. 0. 0. 1.] -> [ True]\n",
      "[0. 0. 1. 0. 1. 0. 0. 0.] -> [False]\n",
      "[0. 0. 1. 0. 0. 1. 1. 1.] -> [False]\n",
      "[0. 0. 1. 0. 0. 1. 1. 0.] -> [ True]\n",
      "[0. 0. 1. 0. 0. 1. 0. 1.] -> [ True]\n",
      "[0. 0. 1. 0. 0. 1. 0. 0.] -> [False]\n",
      "[0. 0. 1. 0. 0. 0. 1. 1.] -> [ True]\n",
      "[0. 0. 1. 0. 0. 0. 1. 0.] -> [False]\n",
      "[0. 0. 1. 0. 0. 0. 0. 1.] -> [False]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0.] -> [ True]\n",
      "[0. 0. 0. 1. 1. 1. 1. 1.] -> [ True]\n",
      "[0. 0. 0. 1. 1. 1. 1. 0.] -> [False]\n",
      "[0. 0. 0. 1. 1. 1. 0. 1.] -> [False]\n",
      "[0. 0. 0. 1. 1. 1. 0. 0.] -> [ True]\n",
      "[0. 0. 0. 1. 1. 0. 1. 1.] -> [False]\n",
      "[0. 0. 0. 1. 1. 0. 1. 0.] -> [ True]\n",
      "[0. 0. 0. 1. 1. 0. 0. 1.] -> [ True]\n",
      "[0. 0. 0. 1. 1. 0. 0. 0.] -> [False]\n",
      "[0. 0. 0. 1. 0. 1. 1. 1.] -> [False]\n",
      "[0. 0. 0. 1. 0. 1. 1. 0.] -> [ True]\n",
      "[0. 0. 0. 1. 0. 1. 0. 1.] -> [ True]\n",
      "[0. 0. 0. 1. 0. 1. 0. 0.] -> [False]\n",
      "[0. 0. 0. 1. 0. 0. 1. 1.] -> [ True]\n",
      "[0. 0. 0. 1. 0. 0. 1. 0.] -> [False]\n",
      "[0. 0. 0. 1. 0. 0. 0. 1.] -> [False]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0.] -> [ True]\n",
      "[0. 0. 0. 0. 1. 1. 1. 1.] -> [False]\n",
      "[0. 0. 0. 0. 1. 1. 1. 0.] -> [ True]\n",
      "[0. 0. 0. 0. 1. 1. 0. 1.] -> [ True]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0.] -> [False]\n",
      "[0. 0. 0. 0. 1. 0. 1. 1.] -> [ True]\n",
      "[0. 0. 0. 0. 1. 0. 1. 0.] -> [False]\n",
      "[0. 0. 0. 0. 1. 0. 0. 1.] -> [False]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0.] -> [ True]\n",
      "[0. 0. 0. 0. 0. 1. 1. 1.] -> [ True]\n",
      "[0. 0. 0. 0. 0. 1. 1. 0.] -> [False]\n",
      "[0. 0. 0. 0. 0. 1. 0. 1.] -> [False]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0.] -> [ True]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1.] -> [False]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0.] -> [ True]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.] -> [ True]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.] -> [False]\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "\n",
    "def xor_reduce(x):\n",
    "    \"\"\"\n",
    "    Computes the XOR reduction on a sequence of bits.\n",
    "\n",
    "    Examples:\n",
    "        100 -> xor(xor(1,0),0) = 1\n",
    "        001 -> xor(xor(0,0),1) = 1\n",
    "        110 -> xor(xor(1,1),0) = 0\n",
    "        011 -> xor(xor(0,1),1) = 0\n",
    "\n",
    "    Args:\n",
    "        x: boolean vector of bits.\n",
    "\n",
    "    Returns:\n",
    "        bool, scalar\n",
    "    \"\"\"\n",
    "    output = x[0]\n",
    "    for i in range(1, x.shape[-1]):\n",
    "        output = jnp.logical_xor(output, x[i])\n",
    "    return output\n",
    "\n",
    "\n",
    "num_variables = 8\n",
    "options = [True, False]\n",
    "x = jnp.asarray(list(product(options, repeat=num_variables)))#N,2\n",
    "y = vmap(xor_reduce)(x)[:, None]#N, 1\n",
    "x = x.astype(jnp.float32)\n",
    "print(\"Data:\")\n",
    "\n",
    "for input, output in zip(x,y):\n",
    "    print(f\"{input} -> {output}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 31\n"
     ]
    }
   ],
   "source": [
    "# Define the likelihood, using Haiku as our framework for neural networks\n",
    "\n",
    "def model(x, is_training=False):\n",
    "    mlp1 = hk.Sequential([hk.Linear(3),\n",
    "                         jax.nn.sigmoid,\n",
    "                          hk.Linear(1)])\n",
    "\n",
    "    return mlp1(x)\n",
    "\n",
    "model = hk.without_apply_rng(hk.transform(model))\n",
    "# We must call the model once to get the params shape and type as a big pytree\n",
    "# We then use ravel_pytree to flatten and get the unflatten function.\n",
    "init_params = model.init(random.PRNGKey(2345), x)\n",
    "init_params_flat, unravel_func = ravel_pytree(init_params)\n",
    "n_dims = init_params_flat.size\n",
    "print(\"Number of parameters:\", n_dims)\n",
    "\n",
    "def softplus(x):\n",
    "    return jnp.log1p(jnp.exp(x))\n",
    "\n",
    "def log_likelihood(params, **kwargs):\n",
    "    \"\"\"\n",
    "    log(P(y|p))\n",
    "    p = exp(logits)/1 - exp(logits)\n",
    "    = log(p) * y + log(1-p) * (1-y)\n",
    "    = logits * y1 - log(exp(-logits)/(exp(-logits) - 1)) * y0\n",
    "    \"\"\"\n",
    "    params_dict = unravel_func(params)\n",
    "    logits = model.apply(params_dict, x)\n",
    "    log_prob0, log_prob1 = -softplus(logits), -softplus(-logits)\n",
    "    #log(p) * y + log(1-p) * (1-y)\n",
    "    log_prob = jnp.mean(jnp.where(y, log_prob1, log_prob0))\n",
    "    return jnp.asarray(log_prob, jnp.float64)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/miniconda3/envs/jax_py/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:2983: UserWarning: Explicitly requested dtype <class 'jax._src.numpy.lax_numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lax._check_user_dtype_supported(dtype, \"asarray\")\n",
      "/home/albert/miniconda3/envs/jax_py/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:2983: UserWarning: Explicitly requested dtype <class 'jax._src.numpy.lax_numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lax._check_user_dtype_supported(dtype, \"asarray\")\n",
      "/home/albert/miniconda3/envs/jax_py/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:2983: UserWarning: Explicitly requested dtype <class 'jax._src.numpy.lax_numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lax._check_user_dtype_supported(dtype, \"asarray\")\n",
      "/home/albert/miniconda3/envs/jax_py/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:2983: UserWarning: Explicitly requested dtype <class 'jax._src.numpy.lax_numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lax._check_user_dtype_supported(dtype, \"asarray\")\n"
     ]
    }
   ],
   "source": [
    "# Let us compare the results of nested sampling to optimisation done with BFGS\n",
    "num_random_init = 100\n",
    "init_keys = random.split(random.PRNGKey(42), num_random_init)\n",
    "params_bfgs = vmap(lambda key: minimize(lambda p: -log_likelihood(p),\n",
    "                   random.normal(key, shape=(n_dims,)),\n",
    "                   method='BFGS').x)(init_keys)\n",
    "log_L_bfgs = vmap(log_likelihood)(params_bfgs)\n",
    "idx_max = jnp.argmax(log_L_bfgs)\n",
    "log_L_bfgs_max = log_L_bfgs[idx_max]\n",
    "params_bfgs_max = params_bfgs[idx_max]\n",
    "print(f\"BFGS maximum likelihood solution of {num_random_init} tries: log(L) = {log_L_bfgs_max}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "with PriorChain() as prior_chain:\n",
    "    # we'll effectively place no prior on the parameters, other than requiring them to be within [-10,10]\n",
    "    UniformPrior('params', -10.*jnp.ones(n_dims), 10.*jnp.ones(n_dims))\n",
    "\n",
    "# We'll do some strange things here.\n",
    "# num_slices -> low: We'll make the sampler do very few slices. This will lead to large correlation between samples, and poor estimate of the evidence.\n",
    "# This is alright, because we'll be looking for the maximum likelihood solution.\n",
    "go = GlobalOptimiser(loglikelihood=log_likelihood, prior_chain=prior_chain,\n",
    "                   num_parallel_samplers=4, sampler_kwargs=dict(gradient_boost=False))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's test the model with a small sanity check.\n",
    "prior_chain.test_prior(random.PRNGKey(42), 10, log_likelihood)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = go(random.PRNGKey(42),termination_frac_likelihood_improvement=1e-3,termination_patience=3,\n",
    "             termination_max_num_likelihood_evaluations=10e6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The maximum likelihood solution from nested sampling\n",
    "params_max = results.sample_L_max['params']\n",
    "log_L_max = results.log_L_max\n",
    "print(\"log L_max(L)\", log_L_max)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "go.summary(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def predict(params):\n",
    "    params_dict = unravel_func(params)\n",
    "    logits = model.apply(params_dict, x)\n",
    "    return jax.nn.sigmoid(logits)[:,0]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = predict(params_max)\n",
    "print(\"Predictions of globally optimised NN:\")\n",
    "for i in range(len(y)):\n",
    "    print(f\"{i}: {x[i]} -> {y[i]} | pred: {predictions[i]}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y[:,0],y_score=predictions, pos_label=1)\n",
    "metric = jnp.abs(1-tpr) + jnp.abs(fpr)\n",
    "idx = plt.argmin(metric)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.scatter(fpr[idx], tpr[idx], label=f'optimal threshold {thresholds[idx]}')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimal_thresh = thresholds[idx]\n",
    "classifications = (predictions > optimal_thresh)\n",
    "accuracy = jnp.mean(classifications == y[:,0])\n",
    "print(f\"accuracy of globally optimised NN with optimal threshold: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = predict(params_bfgs_max)\n",
    "print(\"Predictions of BFGS optimised NN:\")\n",
    "for i in range(len(y)):\n",
    "    print(f\"{i}: {x[i]} -> {y[i]} | pred: {predictions[i]}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y[:,0],y_score=predictions, pos_label=1)\n",
    "metric = jnp.abs(1-tpr) + jnp.abs(fpr)\n",
    "idx = plt.argmin(metric)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.scatter(fpr[idx], tpr[idx], label=f'optimal threshold {thresholds[idx]}')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimal_thresh = thresholds[idx]\n",
    "classifications = (predictions > optimal_thresh)\n",
    "accuracy = jnp.mean(classifications == y[:,0])\n",
    "print(f\"accuracy of BFGS optimised NN with optimal threshold: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}